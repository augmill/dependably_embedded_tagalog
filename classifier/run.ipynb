{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5774a28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/augustmilliken/opt/anaconda3/envs/pya13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from Classifier import *\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8adc12cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x113a21690>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "# torch.set_default_dtype(torch.float64) \n",
    "\n",
    "# bert_model = \"paulbontempo/bert-tagalog-dependency-cl\" \n",
    "# model_type = \"cl\"\n",
    "# bert_model = \"paulbontempo/bert-tagalog-mlm-stage1\"  \n",
    "# model_type = \"s1\" \n",
    "# bert_model = \"google-bert/bert-base-multilingual-cased\"\n",
    "# model_type = \"base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005b8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = \"paulbontempo/bert-tagalog-dependency-cl\" \n",
    "model_type = \"cl\"\n",
    "\n",
    "cl_train_batches = torch.load(f\"../data/cl_train.pt\")\n",
    "cl_dev_batches = torch.load(f\"../data/cl_dev.pt\")\n",
    "cl_test_batches = torch.load(f\"../data/cl_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba198fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------epoch 1-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 105.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7127716846582366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 184.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.6614583134651184\n",
      "Validation f1: 0.660473644733429\n",
      "-------------------------epoch 2-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 133.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5714971873818374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 169.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7161458134651184\n",
      "Validation f1: 0.6958134174346924\n",
      "-------------------------epoch 3-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 70.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4645439335485784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 153.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.734375\n",
      "Validation f1: 0.7116625308990479\n",
      "-------------------------epoch 4-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 113.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4162892263110091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 178.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8984375\n",
      "Validation f1: 0.8849601745605469\n",
      "-------------------------epoch 5-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 105.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3939631584940887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 103.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8958333134651184\n",
      "Validation f1: 0.8837992548942566\n",
      "-------------------------epoch 6-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 104.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3787447722946725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 210.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8958333134651184\n",
      "Validation f1: 0.888904869556427\n",
      "-------------------------epoch 7-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 121.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.36301248593301305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 227.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9010416865348816\n",
      "Validation f1: 0.8905392289161682\n",
      "-------------------------epoch 8-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 125.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3444069812937481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 141.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9036458134651184\n",
      "Validation f1: 0.8937408328056335\n",
      "-------------------------epoch 9-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 128.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3381725244405793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 203.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9114583134651184\n",
      "Validation f1: 0.8954105377197266\n",
      "-------------------------epoch 10-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 88.50it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3401510795442069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 188.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7552083134651184\n",
      "Validation f1: 0.7394776344299316\n",
      "-------------------------epoch 11-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 88.00it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3313246409340603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 189.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9088541865348816\n",
      "Validation f1: 0.8952100872993469\n",
      "-------------------------epoch 12-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 109.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3287978641143659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 123.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9166666865348816\n",
      "Validation f1: 0.9012100100517273\n",
      "-------------------------epoch 13-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 96.24it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3293497329804955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 201.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9088541865348816\n",
      "Validation f1: 0.8947601318359375\n",
      "-------------------------epoch 14-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 109.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.31357689347209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 143.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7395833134651184\n",
      "Validation f1: 0.716059148311615\n",
      "-------------------------epoch 15-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 102.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.33848929623278173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 209.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7369791865348816\n",
      "Validation f1: 0.7089402675628662\n",
      "-------------------------epoch 16-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 93.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.32158139111792167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 201.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9166666865348816\n",
      "Validation f1: 0.9014045596122742\n",
      "-------------------------epoch 17-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 83.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3206468983212622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 141.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7239583134651184\n",
      "Validation f1: 0.6877698302268982\n",
      "-------------------------epoch 18-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 79.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.33086496155436446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 26.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7213541865348816\n",
      "Validation f1: 0.683661937713623\n",
      "-------------------------epoch 19-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 69.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3134533083293496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 163.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7395833134651184\n",
      "Validation f1: 0.7155568599700928\n",
      "-------------------------epoch 20-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 75.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3245579374999535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 151.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7447916865348816\n",
      "Validation f1: 0.7211837768554688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cl_model = Classifier(\n",
    "    dim_in=768,\n",
    "    drop = 0.5\n",
    ")\n",
    "\n",
    "train_losses = fit(\n",
    "    model=cl_model,\n",
    "    train_data=cl_train_batches,\n",
    "    dev_data=cl_dev_batches,\n",
    "    opt=torch.optim.AdamW(params=cl_model.parameters(), lr=1e-3),\n",
    "    loss_fn=nn.BCEWithLogitsLoss(),\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "988b5b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = \"paulbontempo/bert-tagalog-mlm-stage1\"  \n",
    "model_type = \"s1\" \n",
    "\n",
    "s1_train_batches = torch.load(f\"../data/s1_train.pt\")\n",
    "s1_dev_batches = torch.load(f\"../data/s1_dev.pt\")\n",
    "s1_test_batches = torch.load(f\"../data/s1_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b674f7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's1_train_batches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m s1_model = Classifier(\n\u001b[32m      2\u001b[39m     dim_in=\u001b[32m768\u001b[39m\n\u001b[32m      3\u001b[39m )\n\u001b[32m      5\u001b[39m train_losses = fit(\n\u001b[32m      6\u001b[39m     model=s1_model,\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     train_data=\u001b[43ms1_train_batches\u001b[49m,\n\u001b[32m      8\u001b[39m     dev_data=s1_dev_batches,\n\u001b[32m      9\u001b[39m     opt=torch.optim.AdamW(params=s1_model.parameters(), lr=\u001b[32m1e-3\u001b[39m),\n\u001b[32m     10\u001b[39m     loss_fn=nn.BCEWithLogitsLoss(),\n\u001b[32m     11\u001b[39m     epochs=\u001b[32m10\u001b[39m\n\u001b[32m     12\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 's1_train_batches' is not defined"
     ]
    }
   ],
   "source": [
    "s1_model = Classifier(\n",
    "    dim_in=768,\n",
    "    drop=0.5\n",
    ")\n",
    "\n",
    "train_losses = fit(\n",
    "    model=s1_model,\n",
    "    train_data=s1_train_batches,\n",
    "    dev_data=s1_dev_batches,\n",
    "    opt=torch.optim.AdamW(params=s1_model.parameters(), lr=1e-3),\n",
    "    loss_fn=nn.BCEWithLogitsLoss(),\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9cf2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = \"google-bert/bert-base-multilingual-cased\"\n",
    "model_type = \"base\"\n",
    "\n",
    "base_train_batches = torch.load(f\"../data/base_train.pt\")\n",
    "base_dev_batches = torch.load(f\"../data/base_dev.pt\")\n",
    "base_test_batches = torch.load(f\"../data/base_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c87746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------epoch 1-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 130.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6849881439674191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 221.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7838541865348816\n",
      "Validation f1: 0.7730984091758728\n",
      "-------------------------epoch 2-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 130.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5849935194341148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 37.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.828125\n",
      "Validation f1: 0.8022892475128174\n",
      "-------------------------epoch 3-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 90.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.5368575795394618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 129.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8567708134651184\n",
      "Validation f1: 0.8324190974235535\n",
      "-------------------------epoch 4-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 88.85it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.48364607880755167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 230.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8541666865348816\n",
      "Validation f1: 0.829582691192627\n",
      "-------------------------epoch 5-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 133.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.450578592899369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 210.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8515625\n",
      "Validation f1: 0.8272296786308289\n",
      "-------------------------epoch 6-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 119.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.42582660768090225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 311.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8671875\n",
      "Validation f1: 0.8425460457801819\n",
      "-------------------------epoch 7-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 116.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.4064615812243485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 183.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8697916865348816\n",
      "Validation f1: 0.8452911972999573\n",
      "-------------------------epoch 8-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 101.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.3949355911917803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 181.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8723958134651184\n",
      "Validation f1: 0.8477264046669006\n",
      "-------------------------epoch 9-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 116.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.38151218324172786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 159.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.8802083134651184\n",
      "Validation f1: 0.8551214337348938\n",
      "-------------------------epoch 10-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 114.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.36895824423650414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 272.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.875\n",
      "Validation f1: 0.8500722050666809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_model = Classifier(\n",
    "    dim_in=768,\n",
    "    drop=0.5\n",
    ")\n",
    "\n",
    "train_losses = fit(\n",
    "    model=base_model,\n",
    "    train_data=base_train_batches,\n",
    "    dev_data=base_dev_batches,\n",
    "    opt=torch.optim.AdamW(params=base_model.parameters(), lr=1e-4),\n",
    "    loss_fn=nn.BCEWithLogitsLoss(),\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78d7caa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=768, out_features=513, bias=True),\n",
       " Linear(in_features=513, out_features=513, bias=True),\n",
       " Linear(in_features=513, out_features=2, bias=True),\n",
       " ReLU(),\n",
       " Dropout(p=0.5, inplace=False),\n",
       " Sequential(\n",
       "   (0): Linear(in_features=768, out_features=513, bias=True)\n",
       "   (1): ReLU()\n",
       "   (2): Linear(in_features=513, out_features=513, bias=True)\n",
       "   (3): ReLU()\n",
       "   (4): Linear(in_features=513, out_features=2, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(base_model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98a82a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.weight tensor([[ 0.0232,  0.0301, -0.0099,  ..., -0.0077,  0.0038, -0.0298],\n",
      "        [ 0.0253,  0.0160,  0.0354,  ...,  0.0310, -0.0125, -0.0255],\n",
      "        [-0.0054, -0.0267, -0.0241,  ...,  0.0057, -0.0426, -0.0009],\n",
      "        ...,\n",
      "        [-0.0140, -0.0330, -0.0037,  ...,  0.0231,  0.0017, -0.0215],\n",
      "        [-0.0451,  0.0053,  0.0479,  ..., -0.0039,  0.0419, -0.0076],\n",
      "        [-0.0249,  0.0457,  0.0568,  ...,  0.0313, -0.0161,  0.0121]])\n",
      "\n",
      "layer1.bias tensor([ 1.6066e-02, -2.8971e-02,  2.5047e-02, -2.2395e-02, -3.5833e-02,\n",
      "         9.0091e-03, -2.3396e-02, -4.4218e-03,  1.9365e-02, -1.2814e-02,\n",
      "        -1.8259e-02,  2.2704e-02, -1.3349e-02, -2.8090e-03, -4.9226e-02,\n",
      "        -2.3307e-02,  2.7748e-02,  2.2994e-02, -2.9011e-02, -1.9760e-03,\n",
      "        -1.5802e-02,  3.9142e-03,  9.3737e-03, -2.9042e-02, -2.2070e-02,\n",
      "         6.6524e-03, -4.5297e-02, -2.5868e-02,  1.5929e-02,  1.9460e-02,\n",
      "         1.2100e-02, -2.5850e-02,  3.4281e-02, -1.5912e-02, -1.3538e-02,\n",
      "         1.9578e-02,  6.7187e-03,  8.9161e-03,  3.0287e-02, -3.8035e-02,\n",
      "         3.3382e-02,  1.2972e-02,  2.3093e-02, -1.4103e-02, -1.2474e-02,\n",
      "        -2.7988e-02, -3.9037e-03, -6.3606e-03, -2.0424e-02, -3.3254e-02,\n",
      "        -4.6194e-02, -2.3284e-02, -1.4211e-02,  9.5913e-03, -5.9664e-03,\n",
      "         1.8747e-02,  6.9529e-03, -1.4145e-02, -8.4016e-03, -1.4047e-03,\n",
      "        -5.3882e-03,  1.0145e-02, -1.9758e-02,  2.1501e-02,  2.3079e-02,\n",
      "         4.9115e-03,  2.8137e-02, -4.3169e-02, -1.2439e-02,  1.7245e-02,\n",
      "        -4.6188e-03, -1.1700e-02, -5.0761e-02,  7.6208e-03,  2.6996e-02,\n",
      "         2.2800e-02, -2.7108e-02, -3.0948e-02,  6.2852e-03,  1.3339e-03,\n",
      "         6.8959e-03, -2.0060e-02,  4.6166e-02,  1.1418e-02,  1.1076e-02,\n",
      "        -2.2378e-02, -7.0112e-03,  3.6693e-03,  2.4308e-02, -1.2813e-04,\n",
      "        -9.3172e-03,  1.8450e-02, -1.8158e-02,  4.1142e-03,  9.2903e-03,\n",
      "        -3.3055e-03, -9.8990e-03,  1.7034e-02,  1.1753e-02, -2.2357e-02,\n",
      "        -2.8280e-02,  6.7772e-03, -3.4533e-02, -1.7444e-02, -8.3057e-04,\n",
      "         2.0980e-02, -3.9102e-02, -1.0770e-02,  3.0767e-02,  8.9562e-03,\n",
      "        -7.8008e-03,  1.4877e-02, -2.8217e-02,  1.6462e-02, -4.4686e-02,\n",
      "         2.1215e-02, -9.2347e-04,  1.8731e-02, -1.7425e-02, -2.6990e-02,\n",
      "        -1.1004e-02, -9.6398e-03,  5.6419e-03, -9.8668e-03,  2.8968e-02,\n",
      "         3.6731e-02, -1.6388e-02,  2.5787e-02, -7.4266e-03, -1.5641e-02,\n",
      "        -1.1966e-02,  2.7809e-02, -1.2232e-02,  1.9921e-02, -3.1612e-02,\n",
      "         2.2923e-02, -2.3735e-02,  1.7019e-02, -1.9189e-02,  1.2869e-02,\n",
      "         3.5612e-02,  1.9621e-03,  2.4332e-02,  1.6133e-02,  1.2102e-02,\n",
      "        -4.4359e-03, -3.6249e-02, -5.2430e-02, -2.2762e-02,  7.6616e-03,\n",
      "         2.7856e-02,  3.3893e-02, -1.5588e-02, -1.9998e-03, -3.6747e-02,\n",
      "         6.9665e-03,  3.2210e-02,  3.1935e-02, -1.2276e-02, -3.7823e-02,\n",
      "        -1.7102e-02, -1.4961e-02, -2.5736e-02,  2.5613e-02, -6.1888e-03,\n",
      "        -6.0842e-03, -1.5263e-02,  4.6310e-03,  7.7603e-03, -2.6511e-02,\n",
      "         3.3801e-02,  2.1682e-02,  1.0702e-02, -5.5723e-03,  1.5437e-02,\n",
      "         2.3556e-02, -2.0225e-02, -3.3314e-02,  1.6319e-02,  1.0611e-02,\n",
      "         6.4792e-03,  1.3474e-03,  2.3217e-02,  1.4553e-02,  2.3542e-02,\n",
      "         8.3957e-03,  1.1142e-02,  3.2514e-03, -8.9715e-03, -3.3505e-02,\n",
      "        -2.6256e-02, -1.2125e-02,  2.8943e-02,  2.0334e-02, -4.9819e-03,\n",
      "         2.2632e-02,  2.5552e-02, -2.7810e-02,  1.0103e-03, -1.7160e-02,\n",
      "        -1.8968e-02, -1.5119e-02, -1.3133e-02, -3.3772e-02, -3.4721e-02,\n",
      "        -9.2061e-03,  5.2728e-03, -3.3178e-02,  1.2606e-02,  3.0866e-02,\n",
      "         1.8415e-03,  4.1218e-03, -4.3806e-02,  3.3199e-02,  1.8089e-02,\n",
      "         7.6988e-03,  2.2910e-02, -3.7001e-02, -2.5300e-03,  3.6291e-03,\n",
      "        -1.5444e-02,  1.1905e-02, -4.4472e-03,  2.1899e-02, -2.3712e-02,\n",
      "         9.0144e-03, -4.4009e-02, -5.9370e-03, -3.2501e-02,  9.9459e-03,\n",
      "         3.7453e-02,  3.3049e-02,  1.1771e-02,  1.4476e-02, -7.2868e-03,\n",
      "        -2.3591e-02,  1.0353e-02,  2.0902e-02,  1.3935e-02,  7.6568e-04,\n",
      "        -3.0381e-02, -2.5557e-02,  8.5956e-03,  2.0267e-02, -2.3954e-02,\n",
      "         4.0245e-02,  2.7437e-02, -7.9588e-03,  1.0630e-03, -3.2327e-02,\n",
      "        -3.5819e-02, -3.9669e-02, -1.9365e-02, -2.1174e-02, -2.4724e-02,\n",
      "        -1.6731e-02, -3.9013e-02, -2.0879e-02,  1.5316e-02, -3.1690e-02,\n",
      "         2.3577e-02, -2.4050e-02,  2.1308e-02,  2.9489e-02, -2.5264e-03,\n",
      "         1.8939e-02,  1.8404e-02,  1.0807e-02,  3.2577e-02, -2.0280e-02,\n",
      "         9.5727e-03, -1.4795e-02, -1.0058e-02, -1.5955e-02, -3.7288e-02,\n",
      "        -7.5066e-04, -2.2721e-03,  2.5867e-02, -3.7733e-02, -1.9700e-02,\n",
      "         2.0692e-02,  3.8692e-02, -1.5416e-02,  2.0071e-02,  1.8102e-02,\n",
      "         1.2408e-02, -2.4501e-02,  5.7890e-03,  1.6259e-02,  1.5938e-02,\n",
      "        -2.1908e-02,  7.7257e-03, -2.6662e-02, -3.2249e-02, -4.0504e-02,\n",
      "         3.1484e-03,  5.3253e-03,  1.9893e-02, -1.1630e-02,  2.3610e-02,\n",
      "         1.4671e-02, -1.7216e-02,  1.0435e-02,  4.5389e-03,  7.5384e-03,\n",
      "         2.1333e-02,  2.3761e-02,  2.6355e-02,  4.4287e-03,  1.0324e-02,\n",
      "        -1.3770e-02,  2.8491e-02, -1.6724e-04,  2.3742e-02,  3.4556e-02,\n",
      "        -3.2043e-02, -4.3722e-03,  2.3651e-02,  3.1434e-03,  3.2457e-03,\n",
      "        -1.1325e-02, -3.2170e-02, -8.0250e-03, -4.5556e-02, -4.1753e-03,\n",
      "        -2.9017e-02, -9.4915e-03, -2.4402e-02,  3.2857e-02,  1.1205e-02,\n",
      "         6.8587e-03,  3.3249e-02,  9.5841e-03, -1.3932e-02,  2.6730e-02,\n",
      "         3.7851e-02, -4.3735e-04, -2.7371e-02,  1.9310e-03, -1.0817e-02,\n",
      "        -2.5977e-02,  4.7841e-03, -3.0715e-02,  2.1780e-02, -2.7231e-02,\n",
      "        -8.5143e-04,  2.1824e-02, -5.0417e-02,  1.3257e-02, -4.6340e-02,\n",
      "         3.3600e-02, -1.2952e-02, -2.8856e-02,  1.1474e-02, -1.2341e-02,\n",
      "        -3.0092e-02, -6.6101e-03, -1.7842e-02, -1.6025e-02, -6.5930e-03,\n",
      "        -1.4759e-02, -9.0379e-03, -7.5458e-03,  8.2690e-03, -3.4841e-02,\n",
      "         1.6836e-02,  1.3472e-03, -5.8029e-03,  6.8416e-03,  1.7772e-02,\n",
      "        -2.9103e-02,  2.0909e-02,  7.3273e-03, -1.9846e-02, -2.7864e-02,\n",
      "        -8.3927e-03, -3.8956e-03,  1.2610e-02, -5.1757e-03, -1.1013e-02,\n",
      "        -1.4554e-02,  1.4189e-02, -2.0186e-02,  2.3374e-02,  8.1892e-03,\n",
      "         3.1931e-02, -2.9810e-02, -1.4732e-02, -3.5540e-02, -4.2172e-02,\n",
      "        -4.1818e-02, -3.5849e-02,  3.3242e-03, -8.9858e-04, -2.1786e-02,\n",
      "         1.4569e-03,  3.1982e-02,  2.1630e-02, -1.8453e-02, -3.7265e-02,\n",
      "        -3.9349e-02,  5.3193e-03, -8.3555e-03, -2.9359e-04, -1.6603e-02,\n",
      "         1.1298e-02,  1.4803e-02, -2.7572e-02,  1.4823e-03, -2.2125e-02,\n",
      "        -7.3286e-03, -1.5266e-02, -3.2098e-02,  6.4153e-03, -7.5953e-03,\n",
      "         3.8341e-04, -2.7164e-02,  3.3615e-02, -3.2875e-02,  6.9115e-03,\n",
      "        -2.0961e-03,  1.1114e-02,  2.8535e-02,  1.5641e-02,  3.3482e-03,\n",
      "         2.4308e-02, -2.1681e-02, -1.6435e-02, -2.7967e-02,  4.5351e-03,\n",
      "         1.8223e-02,  8.6184e-03, -3.9636e-02, -6.3175e-03, -2.9126e-02,\n",
      "        -3.3512e-02,  4.1060e-03,  8.3505e-04, -7.0473e-03,  2.3509e-02,\n",
      "         2.6999e-02,  2.5136e-02,  1.1498e-02, -2.5395e-02,  2.8678e-02,\n",
      "         1.6863e-02, -1.1372e-02,  8.7625e-03, -2.0794e-02,  2.5690e-02,\n",
      "        -4.1969e-03,  8.6213e-05, -1.0112e-02, -2.3370e-02,  3.1636e-02,\n",
      "        -8.9151e-03, -9.6863e-03,  1.1714e-02, -2.4366e-02, -5.8272e-03,\n",
      "        -1.1488e-02, -3.5622e-02, -3.0893e-02, -1.4822e-02,  2.8212e-02,\n",
      "         2.6330e-02,  3.4716e-03,  1.5497e-03, -2.9493e-02,  3.4410e-02,\n",
      "        -3.4713e-02, -2.3342e-03,  2.9454e-02, -2.0781e-02, -9.1918e-03,\n",
      "        -1.4627e-02,  1.4353e-02, -1.9984e-02, -2.7251e-02, -3.2663e-02,\n",
      "        -3.0710e-02, -2.6042e-02,  2.3128e-02, -1.9836e-02,  4.7821e-02,\n",
      "        -1.6100e-04, -3.2718e-02,  6.6662e-03, -1.0003e-02, -1.9093e-02,\n",
      "         3.4369e-02, -6.0075e-03,  9.0232e-04, -2.5541e-02,  9.2025e-04,\n",
      "         1.8822e-02, -2.2227e-02, -3.2736e-02,  1.3737e-02, -3.2671e-02,\n",
      "         5.2955e-03, -2.6883e-02, -2.4298e-02, -3.1841e-02, -1.4962e-02,\n",
      "         2.2439e-02,  1.3209e-02,  3.8984e-03,  1.0966e-03, -6.2928e-03,\n",
      "        -2.5733e-02,  2.1984e-02,  3.0789e-02])\n",
      "\n",
      "hidden.weight tensor([[ 0.0193, -0.0444, -0.0389,  ..., -0.0061, -0.0279,  0.0070],\n",
      "        [-0.0363, -0.0064, -0.0008,  ..., -0.0148, -0.0424, -0.0458],\n",
      "        [-0.0529, -0.0115, -0.0284,  ...,  0.0091, -0.0114,  0.0260],\n",
      "        ...,\n",
      "        [-0.0187, -0.0216, -0.0354,  ..., -0.0128, -0.0534, -0.0143],\n",
      "        [-0.0414,  0.0136, -0.0480,  ..., -0.0041, -0.0009, -0.0359],\n",
      "        [ 0.0052,  0.0373, -0.0142,  ..., -0.0366,  0.0138, -0.0148]])\n",
      "\n",
      "hidden.bias tensor([ 8.3959e-03,  6.9103e-03, -1.7847e-02, -2.8339e-03,  3.9754e-02,\n",
      "        -6.7194e-03, -3.3355e-02, -4.7238e-02, -8.5782e-03,  1.2168e-02,\n",
      "         2.2359e-03,  3.4261e-02, -1.5823e-02, -3.6894e-02,  6.2626e-03,\n",
      "         2.9006e-02, -3.9007e-03,  2.3658e-03,  1.5163e-02, -7.0050e-03,\n",
      "         4.4386e-02, -1.4853e-02,  2.7098e-02, -1.4885e-03, -8.1438e-03,\n",
      "         2.3443e-02, -3.4319e-02, -5.9321e-03, -9.0544e-03,  3.7840e-02,\n",
      "         4.0716e-02,  3.9152e-02, -1.7938e-02, -4.1329e-03, -1.8493e-02,\n",
      "        -1.9829e-02,  4.3241e-03,  4.5151e-02,  2.1947e-02,  8.4934e-03,\n",
      "        -1.6452e-02,  3.5889e-02, -8.3388e-03, -4.7436e-02,  2.6207e-02,\n",
      "         1.4629e-02, -1.9355e-02,  4.0981e-02,  1.8136e-02, -2.1719e-04,\n",
      "         2.1724e-02, -1.8896e-02, -4.5741e-03,  2.5597e-02,  1.1627e-02,\n",
      "        -1.6322e-03,  1.7462e-02, -6.8830e-03,  1.5675e-02, -4.2939e-02,\n",
      "         3.0719e-02, -1.2746e-03,  4.4764e-02,  7.7269e-03,  2.0118e-02,\n",
      "         7.1680e-04,  4.2012e-02,  1.0149e-02,  1.2704e-02,  2.3339e-02,\n",
      "         4.0114e-02,  1.6812e-02,  1.4704e-02,  3.9938e-02,  1.7876e-02,\n",
      "        -4.9468e-02,  1.6410e-02,  2.0415e-02, -4.7115e-02, -1.9495e-02,\n",
      "        -1.2271e-02, -9.8209e-03, -1.4858e-02,  7.0769e-03, -4.2454e-02,\n",
      "         8.6175e-03, -1.1226e-02,  1.4098e-02,  3.4803e-02,  2.3366e-02,\n",
      "         3.6490e-02, -2.1662e-02,  4.2363e-02,  1.2258e-02,  5.3249e-02,\n",
      "        -3.2591e-02,  7.1050e-03, -4.2775e-02,  3.8324e-02,  4.1263e-02,\n",
      "         5.3137e-03, -2.2953e-02, -6.5985e-03, -3.7388e-02, -3.2628e-02,\n",
      "         8.8388e-03, -6.3709e-03, -1.7225e-02,  1.2936e-02, -2.4003e-02,\n",
      "         1.0102e-02,  1.3346e-02, -2.6022e-02,  4.4665e-03, -2.5901e-02,\n",
      "        -1.4293e-02, -2.2768e-02,  1.0290e-02,  2.8896e-02, -4.2362e-02,\n",
      "         2.4407e-02,  4.4052e-02, -3.7217e-02,  1.5630e-02,  2.6257e-02,\n",
      "        -4.0734e-02,  3.9292e-02, -1.8501e-02,  8.2005e-03,  5.2612e-02,\n",
      "        -3.0877e-02, -9.3181e-03, -2.7842e-02,  3.7383e-02, -6.4579e-02,\n",
      "        -4.8609e-02,  3.2880e-02,  2.4948e-03,  3.7637e-02, -1.6523e-03,\n",
      "         6.6652e-03, -3.3233e-03, -2.1648e-02,  1.7563e-02, -2.2724e-02,\n",
      "         1.8537e-02,  3.5964e-02,  3.2839e-02, -4.2227e-02, -1.6169e-03,\n",
      "         2.8883e-02,  2.7459e-03,  2.1363e-02,  2.8199e-02, -2.6783e-02,\n",
      "         1.9870e-02,  6.8223e-03, -4.2556e-02,  1.2454e-02, -1.4006e-02,\n",
      "         4.2103e-03,  4.2037e-02,  1.7602e-02,  6.6124e-03, -1.0497e-02,\n",
      "         4.2486e-02,  2.7773e-02,  1.8369e-02, -3.3322e-02, -2.9748e-02,\n",
      "        -1.1248e-02,  1.7043e-02,  2.0738e-02,  1.1977e-02, -1.3879e-02,\n",
      "         1.2505e-02,  4.0371e-03, -1.0814e-02, -4.0535e-03,  4.5453e-02,\n",
      "        -3.4463e-02, -1.0347e-02,  4.5174e-02,  7.1507e-03, -1.7812e-02,\n",
      "        -8.9477e-03,  1.3802e-02, -1.0742e-02, -1.1913e-02, -2.8267e-02,\n",
      "        -4.8785e-02, -1.6546e-02, -4.3552e-02,  3.6424e-02,  5.7583e-03,\n",
      "        -7.5132e-03,  1.2523e-03,  3.0928e-02, -3.9494e-02, -9.8472e-03,\n",
      "         6.2659e-03, -2.6143e-02,  2.4198e-02, -2.4898e-02,  3.0824e-02,\n",
      "        -3.7438e-03,  2.0162e-02, -7.1882e-03,  2.7547e-02, -4.1144e-03,\n",
      "         4.8869e-02, -4.9900e-02,  3.1153e-03,  1.3875e-02, -2.4429e-02,\n",
      "        -4.3807e-02,  3.4898e-03,  8.2200e-03, -1.7638e-02,  1.2015e-02,\n",
      "        -3.9950e-02, -8.7672e-03, -3.2907e-02,  1.1121e-02,  2.8620e-02,\n",
      "        -4.3900e-02,  2.0224e-02,  1.1267e-02,  1.1699e-02, -2.4395e-03,\n",
      "        -1.3218e-02, -1.6241e-02, -2.2826e-02,  7.0587e-03, -4.4021e-03,\n",
      "        -8.7321e-03,  2.1059e-02,  2.0047e-02,  4.0395e-02, -2.0510e-03,\n",
      "        -3.7757e-02, -3.2785e-02,  1.0642e-03, -2.7346e-02,  1.0166e-02,\n",
      "        -3.8715e-02,  4.7600e-02,  3.4843e-02,  2.8221e-02, -2.9814e-02,\n",
      "         1.5964e-02, -4.3333e-02,  2.9456e-02,  1.8259e-02,  3.7249e-02,\n",
      "        -2.9853e-02, -4.0734e-02,  2.5682e-02,  4.4924e-02, -3.5256e-02,\n",
      "        -1.3327e-02,  3.9454e-02, -3.1416e-02,  3.1860e-02,  3.6956e-02,\n",
      "        -5.6767e-02, -6.2362e-04, -2.1314e-02,  3.2624e-02,  1.8913e-02,\n",
      "         5.6250e-03, -3.2408e-02,  2.0142e-02, -1.2474e-02,  4.0672e-02,\n",
      "        -1.4894e-02, -2.2850e-02,  9.5147e-03, -2.7187e-03,  3.7777e-02,\n",
      "         2.5228e-02, -4.3213e-02, -2.9576e-03, -3.4516e-02, -5.5338e-03,\n",
      "        -7.8049e-03,  1.7453e-02, -5.0078e-02,  3.6036e-02,  4.2990e-02,\n",
      "        -7.1173e-05,  1.3356e-02,  4.9115e-02,  2.8262e-02, -2.3723e-02,\n",
      "         2.8231e-02, -4.0692e-02,  2.8670e-02,  2.3841e-02,  2.0745e-02,\n",
      "        -1.6199e-03,  2.8266e-02, -3.1517e-02, -4.0114e-02, -4.4856e-02,\n",
      "        -3.2897e-02, -9.8255e-03,  2.6661e-02, -5.3775e-02, -2.5671e-02,\n",
      "         2.0818e-02, -4.8735e-02, -2.3615e-02,  5.3517e-03,  4.1260e-02,\n",
      "         1.0258e-02, -1.6017e-02, -3.2611e-02,  1.7353e-02,  1.4151e-02,\n",
      "        -1.1924e-02, -1.2600e-02, -2.9910e-02,  4.4110e-02, -3.7853e-02,\n",
      "        -5.6561e-02,  2.2590e-02, -2.5489e-02,  4.8014e-03, -4.1356e-02,\n",
      "         3.5773e-02, -2.3238e-02, -3.8241e-02,  1.3557e-02, -2.4738e-02,\n",
      "        -1.8820e-02,  3.8564e-02,  3.3217e-03,  1.8647e-03, -1.5544e-02,\n",
      "         2.7640e-02,  2.3121e-02, -4.0273e-02, -3.4578e-02, -4.2621e-02,\n",
      "        -4.0725e-02,  1.9128e-02, -4.2157e-02, -3.3942e-02,  3.9846e-02,\n",
      "         3.6549e-02, -8.3356e-03, -9.3890e-03,  4.0451e-02, -3.7558e-02,\n",
      "         2.7809e-02,  4.1684e-02,  2.4681e-02, -4.6217e-02, -7.1776e-03,\n",
      "         6.3710e-03, -5.0416e-02, -6.2311e-03, -1.7594e-02,  3.0615e-02,\n",
      "         1.5038e-02,  1.2511e-02, -1.6894e-02, -3.7000e-02, -3.5551e-03,\n",
      "         3.3271e-02, -1.9013e-02, -1.3280e-02,  2.3387e-02,  1.9180e-02,\n",
      "         1.5104e-02,  1.9039e-02,  5.1112e-02,  1.5364e-02, -2.1473e-02,\n",
      "        -1.8519e-02,  1.1881e-02, -4.5377e-02, -5.6976e-02, -3.2869e-03,\n",
      "        -1.7052e-02,  1.7161e-02,  3.0024e-02,  2.8059e-03,  5.9286e-03,\n",
      "         4.6121e-02,  3.3057e-03,  3.3857e-02,  5.9016e-04,  3.8348e-02,\n",
      "        -2.6047e-03,  1.9511e-02, -4.2380e-02,  4.3664e-02,  7.3854e-03,\n",
      "         3.2525e-02,  1.9355e-02,  6.6365e-03, -1.3509e-02, -4.0637e-03,\n",
      "        -3.4859e-02,  3.0477e-02, -3.1458e-02,  1.2208e-02, -4.0123e-02,\n",
      "         1.1323e-02,  1.8242e-02, -5.6842e-03,  2.2110e-02,  2.0278e-02,\n",
      "        -3.1313e-02, -1.5137e-02, -1.1033e-02, -4.1569e-02,  4.3571e-02,\n",
      "         3.6675e-03, -3.3870e-02,  4.9932e-03, -1.3928e-02,  3.6087e-02,\n",
      "        -8.6204e-03,  3.8794e-03,  2.3598e-02,  4.0830e-02, -3.0477e-03,\n",
      "         4.7426e-03,  2.4890e-02,  4.3431e-02, -6.1526e-03,  3.7884e-02,\n",
      "        -3.6587e-02,  2.1115e-03, -3.8675e-02, -1.1610e-02,  4.3417e-02,\n",
      "        -2.0654e-02,  2.1316e-02, -3.7914e-03, -3.6892e-02,  2.4409e-02,\n",
      "        -5.3010e-02,  2.1452e-02,  3.0718e-02,  8.0704e-03, -9.5846e-03,\n",
      "        -4.6025e-02,  1.3719e-02,  2.2553e-02,  1.5832e-02,  3.8374e-02,\n",
      "         3.8934e-02,  3.3984e-02, -3.8118e-02, -2.2965e-02,  5.8979e-03,\n",
      "         8.9528e-03,  3.9822e-02, -5.7402e-02, -3.1352e-02,  3.2958e-02,\n",
      "         4.7293e-02,  6.1907e-03, -4.7631e-02, -5.1262e-02,  3.2816e-02,\n",
      "         2.7599e-02, -2.1026e-02,  1.4252e-02,  4.8910e-02,  2.6630e-02,\n",
      "         1.3188e-02,  1.5300e-02,  3.2412e-02,  3.6161e-03,  2.0673e-02,\n",
      "        -1.5143e-02,  4.4975e-02,  1.1746e-02, -1.5082e-02,  2.8290e-02,\n",
      "         2.0903e-02, -1.9197e-02,  4.1453e-02,  1.9319e-02, -2.3898e-02,\n",
      "         3.7104e-02,  2.4168e-02,  1.4162e-02, -4.7530e-02, -4.5711e-02,\n",
      "        -1.0275e-02, -1.1012e-03,  1.2832e-02, -7.5094e-03, -4.0453e-02,\n",
      "         3.8734e-02, -5.3093e-03,  2.6647e-02,  1.4739e-02, -4.6176e-02,\n",
      "        -3.0983e-02,  4.0199e-02,  2.2710e-02,  1.6516e-02, -4.9483e-02,\n",
      "         4.5224e-02, -5.1847e-02,  1.6728e-02])\n",
      "\n",
      "layer2.weight tensor([[ 0.0059,  0.0532, -0.0324,  ...,  0.0119,  0.0058,  0.0545],\n",
      "        [-0.0014,  0.0140,  0.0141,  ..., -0.0198,  0.0099,  0.0229]])\n",
      "\n",
      "layer2.bias tensor([0.0290, 0.0138])\n",
      "\n",
      "model.0.weight tensor([[ 0.0232,  0.0301, -0.0099,  ..., -0.0077,  0.0038, -0.0298],\n",
      "        [ 0.0253,  0.0160,  0.0354,  ...,  0.0310, -0.0125, -0.0255],\n",
      "        [-0.0054, -0.0267, -0.0241,  ...,  0.0057, -0.0426, -0.0009],\n",
      "        ...,\n",
      "        [-0.0140, -0.0330, -0.0037,  ...,  0.0231,  0.0017, -0.0215],\n",
      "        [-0.0451,  0.0053,  0.0479,  ..., -0.0039,  0.0419, -0.0076],\n",
      "        [-0.0249,  0.0457,  0.0568,  ...,  0.0313, -0.0161,  0.0121]])\n",
      "\n",
      "model.0.bias tensor([ 1.6066e-02, -2.8971e-02,  2.5047e-02, -2.2395e-02, -3.5833e-02,\n",
      "         9.0091e-03, -2.3396e-02, -4.4218e-03,  1.9365e-02, -1.2814e-02,\n",
      "        -1.8259e-02,  2.2704e-02, -1.3349e-02, -2.8090e-03, -4.9226e-02,\n",
      "        -2.3307e-02,  2.7748e-02,  2.2994e-02, -2.9011e-02, -1.9760e-03,\n",
      "        -1.5802e-02,  3.9142e-03,  9.3737e-03, -2.9042e-02, -2.2070e-02,\n",
      "         6.6524e-03, -4.5297e-02, -2.5868e-02,  1.5929e-02,  1.9460e-02,\n",
      "         1.2100e-02, -2.5850e-02,  3.4281e-02, -1.5912e-02, -1.3538e-02,\n",
      "         1.9578e-02,  6.7187e-03,  8.9161e-03,  3.0287e-02, -3.8035e-02,\n",
      "         3.3382e-02,  1.2972e-02,  2.3093e-02, -1.4103e-02, -1.2474e-02,\n",
      "        -2.7988e-02, -3.9037e-03, -6.3606e-03, -2.0424e-02, -3.3254e-02,\n",
      "        -4.6194e-02, -2.3284e-02, -1.4211e-02,  9.5913e-03, -5.9664e-03,\n",
      "         1.8747e-02,  6.9529e-03, -1.4145e-02, -8.4016e-03, -1.4047e-03,\n",
      "        -5.3882e-03,  1.0145e-02, -1.9758e-02,  2.1501e-02,  2.3079e-02,\n",
      "         4.9115e-03,  2.8137e-02, -4.3169e-02, -1.2439e-02,  1.7245e-02,\n",
      "        -4.6188e-03, -1.1700e-02, -5.0761e-02,  7.6208e-03,  2.6996e-02,\n",
      "         2.2800e-02, -2.7108e-02, -3.0948e-02,  6.2852e-03,  1.3339e-03,\n",
      "         6.8959e-03, -2.0060e-02,  4.6166e-02,  1.1418e-02,  1.1076e-02,\n",
      "        -2.2378e-02, -7.0112e-03,  3.6693e-03,  2.4308e-02, -1.2813e-04,\n",
      "        -9.3172e-03,  1.8450e-02, -1.8158e-02,  4.1142e-03,  9.2903e-03,\n",
      "        -3.3055e-03, -9.8990e-03,  1.7034e-02,  1.1753e-02, -2.2357e-02,\n",
      "        -2.8280e-02,  6.7772e-03, -3.4533e-02, -1.7444e-02, -8.3057e-04,\n",
      "         2.0980e-02, -3.9102e-02, -1.0770e-02,  3.0767e-02,  8.9562e-03,\n",
      "        -7.8008e-03,  1.4877e-02, -2.8217e-02,  1.6462e-02, -4.4686e-02,\n",
      "         2.1215e-02, -9.2347e-04,  1.8731e-02, -1.7425e-02, -2.6990e-02,\n",
      "        -1.1004e-02, -9.6398e-03,  5.6419e-03, -9.8668e-03,  2.8968e-02,\n",
      "         3.6731e-02, -1.6388e-02,  2.5787e-02, -7.4266e-03, -1.5641e-02,\n",
      "        -1.1966e-02,  2.7809e-02, -1.2232e-02,  1.9921e-02, -3.1612e-02,\n",
      "         2.2923e-02, -2.3735e-02,  1.7019e-02, -1.9189e-02,  1.2869e-02,\n",
      "         3.5612e-02,  1.9621e-03,  2.4332e-02,  1.6133e-02,  1.2102e-02,\n",
      "        -4.4359e-03, -3.6249e-02, -5.2430e-02, -2.2762e-02,  7.6616e-03,\n",
      "         2.7856e-02,  3.3893e-02, -1.5588e-02, -1.9998e-03, -3.6747e-02,\n",
      "         6.9665e-03,  3.2210e-02,  3.1935e-02, -1.2276e-02, -3.7823e-02,\n",
      "        -1.7102e-02, -1.4961e-02, -2.5736e-02,  2.5613e-02, -6.1888e-03,\n",
      "        -6.0842e-03, -1.5263e-02,  4.6310e-03,  7.7603e-03, -2.6511e-02,\n",
      "         3.3801e-02,  2.1682e-02,  1.0702e-02, -5.5723e-03,  1.5437e-02,\n",
      "         2.3556e-02, -2.0225e-02, -3.3314e-02,  1.6319e-02,  1.0611e-02,\n",
      "         6.4792e-03,  1.3474e-03,  2.3217e-02,  1.4553e-02,  2.3542e-02,\n",
      "         8.3957e-03,  1.1142e-02,  3.2514e-03, -8.9715e-03, -3.3505e-02,\n",
      "        -2.6256e-02, -1.2125e-02,  2.8943e-02,  2.0334e-02, -4.9819e-03,\n",
      "         2.2632e-02,  2.5552e-02, -2.7810e-02,  1.0103e-03, -1.7160e-02,\n",
      "        -1.8968e-02, -1.5119e-02, -1.3133e-02, -3.3772e-02, -3.4721e-02,\n",
      "        -9.2061e-03,  5.2728e-03, -3.3178e-02,  1.2606e-02,  3.0866e-02,\n",
      "         1.8415e-03,  4.1218e-03, -4.3806e-02,  3.3199e-02,  1.8089e-02,\n",
      "         7.6988e-03,  2.2910e-02, -3.7001e-02, -2.5300e-03,  3.6291e-03,\n",
      "        -1.5444e-02,  1.1905e-02, -4.4472e-03,  2.1899e-02, -2.3712e-02,\n",
      "         9.0144e-03, -4.4009e-02, -5.9370e-03, -3.2501e-02,  9.9459e-03,\n",
      "         3.7453e-02,  3.3049e-02,  1.1771e-02,  1.4476e-02, -7.2868e-03,\n",
      "        -2.3591e-02,  1.0353e-02,  2.0902e-02,  1.3935e-02,  7.6568e-04,\n",
      "        -3.0381e-02, -2.5557e-02,  8.5956e-03,  2.0267e-02, -2.3954e-02,\n",
      "         4.0245e-02,  2.7437e-02, -7.9588e-03,  1.0630e-03, -3.2327e-02,\n",
      "        -3.5819e-02, -3.9669e-02, -1.9365e-02, -2.1174e-02, -2.4724e-02,\n",
      "        -1.6731e-02, -3.9013e-02, -2.0879e-02,  1.5316e-02, -3.1690e-02,\n",
      "         2.3577e-02, -2.4050e-02,  2.1308e-02,  2.9489e-02, -2.5264e-03,\n",
      "         1.8939e-02,  1.8404e-02,  1.0807e-02,  3.2577e-02, -2.0280e-02,\n",
      "         9.5727e-03, -1.4795e-02, -1.0058e-02, -1.5955e-02, -3.7288e-02,\n",
      "        -7.5066e-04, -2.2721e-03,  2.5867e-02, -3.7733e-02, -1.9700e-02,\n",
      "         2.0692e-02,  3.8692e-02, -1.5416e-02,  2.0071e-02,  1.8102e-02,\n",
      "         1.2408e-02, -2.4501e-02,  5.7890e-03,  1.6259e-02,  1.5938e-02,\n",
      "        -2.1908e-02,  7.7257e-03, -2.6662e-02, -3.2249e-02, -4.0504e-02,\n",
      "         3.1484e-03,  5.3253e-03,  1.9893e-02, -1.1630e-02,  2.3610e-02,\n",
      "         1.4671e-02, -1.7216e-02,  1.0435e-02,  4.5389e-03,  7.5384e-03,\n",
      "         2.1333e-02,  2.3761e-02,  2.6355e-02,  4.4287e-03,  1.0324e-02,\n",
      "        -1.3770e-02,  2.8491e-02, -1.6724e-04,  2.3742e-02,  3.4556e-02,\n",
      "        -3.2043e-02, -4.3722e-03,  2.3651e-02,  3.1434e-03,  3.2457e-03,\n",
      "        -1.1325e-02, -3.2170e-02, -8.0250e-03, -4.5556e-02, -4.1753e-03,\n",
      "        -2.9017e-02, -9.4915e-03, -2.4402e-02,  3.2857e-02,  1.1205e-02,\n",
      "         6.8587e-03,  3.3249e-02,  9.5841e-03, -1.3932e-02,  2.6730e-02,\n",
      "         3.7851e-02, -4.3735e-04, -2.7371e-02,  1.9310e-03, -1.0817e-02,\n",
      "        -2.5977e-02,  4.7841e-03, -3.0715e-02,  2.1780e-02, -2.7231e-02,\n",
      "        -8.5143e-04,  2.1824e-02, -5.0417e-02,  1.3257e-02, -4.6340e-02,\n",
      "         3.3600e-02, -1.2952e-02, -2.8856e-02,  1.1474e-02, -1.2341e-02,\n",
      "        -3.0092e-02, -6.6101e-03, -1.7842e-02, -1.6025e-02, -6.5930e-03,\n",
      "        -1.4759e-02, -9.0379e-03, -7.5458e-03,  8.2690e-03, -3.4841e-02,\n",
      "         1.6836e-02,  1.3472e-03, -5.8029e-03,  6.8416e-03,  1.7772e-02,\n",
      "        -2.9103e-02,  2.0909e-02,  7.3273e-03, -1.9846e-02, -2.7864e-02,\n",
      "        -8.3927e-03, -3.8956e-03,  1.2610e-02, -5.1757e-03, -1.1013e-02,\n",
      "        -1.4554e-02,  1.4189e-02, -2.0186e-02,  2.3374e-02,  8.1892e-03,\n",
      "         3.1931e-02, -2.9810e-02, -1.4732e-02, -3.5540e-02, -4.2172e-02,\n",
      "        -4.1818e-02, -3.5849e-02,  3.3242e-03, -8.9858e-04, -2.1786e-02,\n",
      "         1.4569e-03,  3.1982e-02,  2.1630e-02, -1.8453e-02, -3.7265e-02,\n",
      "        -3.9349e-02,  5.3193e-03, -8.3555e-03, -2.9359e-04, -1.6603e-02,\n",
      "         1.1298e-02,  1.4803e-02, -2.7572e-02,  1.4823e-03, -2.2125e-02,\n",
      "        -7.3286e-03, -1.5266e-02, -3.2098e-02,  6.4153e-03, -7.5953e-03,\n",
      "         3.8341e-04, -2.7164e-02,  3.3615e-02, -3.2875e-02,  6.9115e-03,\n",
      "        -2.0961e-03,  1.1114e-02,  2.8535e-02,  1.5641e-02,  3.3482e-03,\n",
      "         2.4308e-02, -2.1681e-02, -1.6435e-02, -2.7967e-02,  4.5351e-03,\n",
      "         1.8223e-02,  8.6184e-03, -3.9636e-02, -6.3175e-03, -2.9126e-02,\n",
      "        -3.3512e-02,  4.1060e-03,  8.3505e-04, -7.0473e-03,  2.3509e-02,\n",
      "         2.6999e-02,  2.5136e-02,  1.1498e-02, -2.5395e-02,  2.8678e-02,\n",
      "         1.6863e-02, -1.1372e-02,  8.7625e-03, -2.0794e-02,  2.5690e-02,\n",
      "        -4.1969e-03,  8.6213e-05, -1.0112e-02, -2.3370e-02,  3.1636e-02,\n",
      "        -8.9151e-03, -9.6863e-03,  1.1714e-02, -2.4366e-02, -5.8272e-03,\n",
      "        -1.1488e-02, -3.5622e-02, -3.0893e-02, -1.4822e-02,  2.8212e-02,\n",
      "         2.6330e-02,  3.4716e-03,  1.5497e-03, -2.9493e-02,  3.4410e-02,\n",
      "        -3.4713e-02, -2.3342e-03,  2.9454e-02, -2.0781e-02, -9.1918e-03,\n",
      "        -1.4627e-02,  1.4353e-02, -1.9984e-02, -2.7251e-02, -3.2663e-02,\n",
      "        -3.0710e-02, -2.6042e-02,  2.3128e-02, -1.9836e-02,  4.7821e-02,\n",
      "        -1.6100e-04, -3.2718e-02,  6.6662e-03, -1.0003e-02, -1.9093e-02,\n",
      "         3.4369e-02, -6.0075e-03,  9.0232e-04, -2.5541e-02,  9.2025e-04,\n",
      "         1.8822e-02, -2.2227e-02, -3.2736e-02,  1.3737e-02, -3.2671e-02,\n",
      "         5.2955e-03, -2.6883e-02, -2.4298e-02, -3.1841e-02, -1.4962e-02,\n",
      "         2.2439e-02,  1.3209e-02,  3.8984e-03,  1.0966e-03, -6.2928e-03,\n",
      "        -2.5733e-02,  2.1984e-02,  3.0789e-02])\n",
      "\n",
      "model.2.weight tensor([[ 0.0193, -0.0444, -0.0389,  ..., -0.0061, -0.0279,  0.0070],\n",
      "        [-0.0363, -0.0064, -0.0008,  ..., -0.0148, -0.0424, -0.0458],\n",
      "        [-0.0529, -0.0115, -0.0284,  ...,  0.0091, -0.0114,  0.0260],\n",
      "        ...,\n",
      "        [-0.0187, -0.0216, -0.0354,  ..., -0.0128, -0.0534, -0.0143],\n",
      "        [-0.0414,  0.0136, -0.0480,  ..., -0.0041, -0.0009, -0.0359],\n",
      "        [ 0.0052,  0.0373, -0.0142,  ..., -0.0366,  0.0138, -0.0148]])\n",
      "\n",
      "model.2.bias tensor([ 8.3959e-03,  6.9103e-03, -1.7847e-02, -2.8339e-03,  3.9754e-02,\n",
      "        -6.7194e-03, -3.3355e-02, -4.7238e-02, -8.5782e-03,  1.2168e-02,\n",
      "         2.2359e-03,  3.4261e-02, -1.5823e-02, -3.6894e-02,  6.2626e-03,\n",
      "         2.9006e-02, -3.9007e-03,  2.3658e-03,  1.5163e-02, -7.0050e-03,\n",
      "         4.4386e-02, -1.4853e-02,  2.7098e-02, -1.4885e-03, -8.1438e-03,\n",
      "         2.3443e-02, -3.4319e-02, -5.9321e-03, -9.0544e-03,  3.7840e-02,\n",
      "         4.0716e-02,  3.9152e-02, -1.7938e-02, -4.1329e-03, -1.8493e-02,\n",
      "        -1.9829e-02,  4.3241e-03,  4.5151e-02,  2.1947e-02,  8.4934e-03,\n",
      "        -1.6452e-02,  3.5889e-02, -8.3388e-03, -4.7436e-02,  2.6207e-02,\n",
      "         1.4629e-02, -1.9355e-02,  4.0981e-02,  1.8136e-02, -2.1719e-04,\n",
      "         2.1724e-02, -1.8896e-02, -4.5741e-03,  2.5597e-02,  1.1627e-02,\n",
      "        -1.6322e-03,  1.7462e-02, -6.8830e-03,  1.5675e-02, -4.2939e-02,\n",
      "         3.0719e-02, -1.2746e-03,  4.4764e-02,  7.7269e-03,  2.0118e-02,\n",
      "         7.1680e-04,  4.2012e-02,  1.0149e-02,  1.2704e-02,  2.3339e-02,\n",
      "         4.0114e-02,  1.6812e-02,  1.4704e-02,  3.9938e-02,  1.7876e-02,\n",
      "        -4.9468e-02,  1.6410e-02,  2.0415e-02, -4.7115e-02, -1.9495e-02,\n",
      "        -1.2271e-02, -9.8209e-03, -1.4858e-02,  7.0769e-03, -4.2454e-02,\n",
      "         8.6175e-03, -1.1226e-02,  1.4098e-02,  3.4803e-02,  2.3366e-02,\n",
      "         3.6490e-02, -2.1662e-02,  4.2363e-02,  1.2258e-02,  5.3249e-02,\n",
      "        -3.2591e-02,  7.1050e-03, -4.2775e-02,  3.8324e-02,  4.1263e-02,\n",
      "         5.3137e-03, -2.2953e-02, -6.5985e-03, -3.7388e-02, -3.2628e-02,\n",
      "         8.8388e-03, -6.3709e-03, -1.7225e-02,  1.2936e-02, -2.4003e-02,\n",
      "         1.0102e-02,  1.3346e-02, -2.6022e-02,  4.4665e-03, -2.5901e-02,\n",
      "        -1.4293e-02, -2.2768e-02,  1.0290e-02,  2.8896e-02, -4.2362e-02,\n",
      "         2.4407e-02,  4.4052e-02, -3.7217e-02,  1.5630e-02,  2.6257e-02,\n",
      "        -4.0734e-02,  3.9292e-02, -1.8501e-02,  8.2005e-03,  5.2612e-02,\n",
      "        -3.0877e-02, -9.3181e-03, -2.7842e-02,  3.7383e-02, -6.4579e-02,\n",
      "        -4.8609e-02,  3.2880e-02,  2.4948e-03,  3.7637e-02, -1.6523e-03,\n",
      "         6.6652e-03, -3.3233e-03, -2.1648e-02,  1.7563e-02, -2.2724e-02,\n",
      "         1.8537e-02,  3.5964e-02,  3.2839e-02, -4.2227e-02, -1.6169e-03,\n",
      "         2.8883e-02,  2.7459e-03,  2.1363e-02,  2.8199e-02, -2.6783e-02,\n",
      "         1.9870e-02,  6.8223e-03, -4.2556e-02,  1.2454e-02, -1.4006e-02,\n",
      "         4.2103e-03,  4.2037e-02,  1.7602e-02,  6.6124e-03, -1.0497e-02,\n",
      "         4.2486e-02,  2.7773e-02,  1.8369e-02, -3.3322e-02, -2.9748e-02,\n",
      "        -1.1248e-02,  1.7043e-02,  2.0738e-02,  1.1977e-02, -1.3879e-02,\n",
      "         1.2505e-02,  4.0371e-03, -1.0814e-02, -4.0535e-03,  4.5453e-02,\n",
      "        -3.4463e-02, -1.0347e-02,  4.5174e-02,  7.1507e-03, -1.7812e-02,\n",
      "        -8.9477e-03,  1.3802e-02, -1.0742e-02, -1.1913e-02, -2.8267e-02,\n",
      "        -4.8785e-02, -1.6546e-02, -4.3552e-02,  3.6424e-02,  5.7583e-03,\n",
      "        -7.5132e-03,  1.2523e-03,  3.0928e-02, -3.9494e-02, -9.8472e-03,\n",
      "         6.2659e-03, -2.6143e-02,  2.4198e-02, -2.4898e-02,  3.0824e-02,\n",
      "        -3.7438e-03,  2.0162e-02, -7.1882e-03,  2.7547e-02, -4.1144e-03,\n",
      "         4.8869e-02, -4.9900e-02,  3.1153e-03,  1.3875e-02, -2.4429e-02,\n",
      "        -4.3807e-02,  3.4898e-03,  8.2200e-03, -1.7638e-02,  1.2015e-02,\n",
      "        -3.9950e-02, -8.7672e-03, -3.2907e-02,  1.1121e-02,  2.8620e-02,\n",
      "        -4.3900e-02,  2.0224e-02,  1.1267e-02,  1.1699e-02, -2.4395e-03,\n",
      "        -1.3218e-02, -1.6241e-02, -2.2826e-02,  7.0587e-03, -4.4021e-03,\n",
      "        -8.7321e-03,  2.1059e-02,  2.0047e-02,  4.0395e-02, -2.0510e-03,\n",
      "        -3.7757e-02, -3.2785e-02,  1.0642e-03, -2.7346e-02,  1.0166e-02,\n",
      "        -3.8715e-02,  4.7600e-02,  3.4843e-02,  2.8221e-02, -2.9814e-02,\n",
      "         1.5964e-02, -4.3333e-02,  2.9456e-02,  1.8259e-02,  3.7249e-02,\n",
      "        -2.9853e-02, -4.0734e-02,  2.5682e-02,  4.4924e-02, -3.5256e-02,\n",
      "        -1.3327e-02,  3.9454e-02, -3.1416e-02,  3.1860e-02,  3.6956e-02,\n",
      "        -5.6767e-02, -6.2362e-04, -2.1314e-02,  3.2624e-02,  1.8913e-02,\n",
      "         5.6250e-03, -3.2408e-02,  2.0142e-02, -1.2474e-02,  4.0672e-02,\n",
      "        -1.4894e-02, -2.2850e-02,  9.5147e-03, -2.7187e-03,  3.7777e-02,\n",
      "         2.5228e-02, -4.3213e-02, -2.9576e-03, -3.4516e-02, -5.5338e-03,\n",
      "        -7.8049e-03,  1.7453e-02, -5.0078e-02,  3.6036e-02,  4.2990e-02,\n",
      "        -7.1173e-05,  1.3356e-02,  4.9115e-02,  2.8262e-02, -2.3723e-02,\n",
      "         2.8231e-02, -4.0692e-02,  2.8670e-02,  2.3841e-02,  2.0745e-02,\n",
      "        -1.6199e-03,  2.8266e-02, -3.1517e-02, -4.0114e-02, -4.4856e-02,\n",
      "        -3.2897e-02, -9.8255e-03,  2.6661e-02, -5.3775e-02, -2.5671e-02,\n",
      "         2.0818e-02, -4.8735e-02, -2.3615e-02,  5.3517e-03,  4.1260e-02,\n",
      "         1.0258e-02, -1.6017e-02, -3.2611e-02,  1.7353e-02,  1.4151e-02,\n",
      "        -1.1924e-02, -1.2600e-02, -2.9910e-02,  4.4110e-02, -3.7853e-02,\n",
      "        -5.6561e-02,  2.2590e-02, -2.5489e-02,  4.8014e-03, -4.1356e-02,\n",
      "         3.5773e-02, -2.3238e-02, -3.8241e-02,  1.3557e-02, -2.4738e-02,\n",
      "        -1.8820e-02,  3.8564e-02,  3.3217e-03,  1.8647e-03, -1.5544e-02,\n",
      "         2.7640e-02,  2.3121e-02, -4.0273e-02, -3.4578e-02, -4.2621e-02,\n",
      "        -4.0725e-02,  1.9128e-02, -4.2157e-02, -3.3942e-02,  3.9846e-02,\n",
      "         3.6549e-02, -8.3356e-03, -9.3890e-03,  4.0451e-02, -3.7558e-02,\n",
      "         2.7809e-02,  4.1684e-02,  2.4681e-02, -4.6217e-02, -7.1776e-03,\n",
      "         6.3710e-03, -5.0416e-02, -6.2311e-03, -1.7594e-02,  3.0615e-02,\n",
      "         1.5038e-02,  1.2511e-02, -1.6894e-02, -3.7000e-02, -3.5551e-03,\n",
      "         3.3271e-02, -1.9013e-02, -1.3280e-02,  2.3387e-02,  1.9180e-02,\n",
      "         1.5104e-02,  1.9039e-02,  5.1112e-02,  1.5364e-02, -2.1473e-02,\n",
      "        -1.8519e-02,  1.1881e-02, -4.5377e-02, -5.6976e-02, -3.2869e-03,\n",
      "        -1.7052e-02,  1.7161e-02,  3.0024e-02,  2.8059e-03,  5.9286e-03,\n",
      "         4.6121e-02,  3.3057e-03,  3.3857e-02,  5.9016e-04,  3.8348e-02,\n",
      "        -2.6047e-03,  1.9511e-02, -4.2380e-02,  4.3664e-02,  7.3854e-03,\n",
      "         3.2525e-02,  1.9355e-02,  6.6365e-03, -1.3509e-02, -4.0637e-03,\n",
      "        -3.4859e-02,  3.0477e-02, -3.1458e-02,  1.2208e-02, -4.0123e-02,\n",
      "         1.1323e-02,  1.8242e-02, -5.6842e-03,  2.2110e-02,  2.0278e-02,\n",
      "        -3.1313e-02, -1.5137e-02, -1.1033e-02, -4.1569e-02,  4.3571e-02,\n",
      "         3.6675e-03, -3.3870e-02,  4.9932e-03, -1.3928e-02,  3.6087e-02,\n",
      "        -8.6204e-03,  3.8794e-03,  2.3598e-02,  4.0830e-02, -3.0477e-03,\n",
      "         4.7426e-03,  2.4890e-02,  4.3431e-02, -6.1526e-03,  3.7884e-02,\n",
      "        -3.6587e-02,  2.1115e-03, -3.8675e-02, -1.1610e-02,  4.3417e-02,\n",
      "        -2.0654e-02,  2.1316e-02, -3.7914e-03, -3.6892e-02,  2.4409e-02,\n",
      "        -5.3010e-02,  2.1452e-02,  3.0718e-02,  8.0704e-03, -9.5846e-03,\n",
      "        -4.6025e-02,  1.3719e-02,  2.2553e-02,  1.5832e-02,  3.8374e-02,\n",
      "         3.8934e-02,  3.3984e-02, -3.8118e-02, -2.2965e-02,  5.8979e-03,\n",
      "         8.9528e-03,  3.9822e-02, -5.7402e-02, -3.1352e-02,  3.2958e-02,\n",
      "         4.7293e-02,  6.1907e-03, -4.7631e-02, -5.1262e-02,  3.2816e-02,\n",
      "         2.7599e-02, -2.1026e-02,  1.4252e-02,  4.8910e-02,  2.6630e-02,\n",
      "         1.3188e-02,  1.5300e-02,  3.2412e-02,  3.6161e-03,  2.0673e-02,\n",
      "        -1.5143e-02,  4.4975e-02,  1.1746e-02, -1.5082e-02,  2.8290e-02,\n",
      "         2.0903e-02, -1.9197e-02,  4.1453e-02,  1.9319e-02, -2.3898e-02,\n",
      "         3.7104e-02,  2.4168e-02,  1.4162e-02, -4.7530e-02, -4.5711e-02,\n",
      "        -1.0275e-02, -1.1012e-03,  1.2832e-02, -7.5094e-03, -4.0453e-02,\n",
      "         3.8734e-02, -5.3093e-03,  2.6647e-02,  1.4739e-02, -4.6176e-02,\n",
      "        -3.0983e-02,  4.0199e-02,  2.2710e-02,  1.6516e-02, -4.9483e-02,\n",
      "         4.5224e-02, -5.1847e-02,  1.6728e-02])\n",
      "\n",
      "model.4.weight tensor([[ 0.0059,  0.0532, -0.0324,  ...,  0.0119,  0.0058,  0.0545],\n",
      "        [-0.0014,  0.0140,  0.0141,  ..., -0.0198,  0.0099,  0.0229]])\n",
      "\n",
      "model.4.bias tensor([0.0290, 0.0138])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key, value in base_model.state_dict().items():\n",
    "    print(key, value)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ce31a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pya13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
